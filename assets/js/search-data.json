{
  
    
        "post0": {
            "title": "Building a multiclass classification model",
            "content": "Introduction . At the Fall 2021 ACS Meeting, the group from NCATS described a number of ADME models they had developed. Even better, the NCATS team also released some of the data used to build these models. In this notebook we&#39;ll use the data from the NCATS CYP3A4 assay to classify molecules as CYP3A4 activators, inhibitors, or inactive. . In order to run this notebook, the following Python libraries should be installed . pandas - handling data tables | pubchempy - grabbing chemical structures from PubChem | tqdm - progress bars | numpy - linear algebra and matrices | itertools - advanced list handling | sklearn - machine learning | lightgbm - gradient boosted trees for machine learning | matplotlib - plotting | seaborn - even better plotting | pingouin - stats | imbalanced-learning - machine learning with imbalanced datasets | . import pandas as pd import pubchempy as pcp from tqdm.auto import tqdm import numpy as np import itertools from lib.descriptor_gen import DescriptorGen from sklearn.preprocessing import LabelEncoder from sklearn.model_selection import train_test_split from lightgbm import LGBMClassifier from sklearn.metrics import plot_confusion_matrix, matthews_corrcoef, roc_auc_score import matplotlib.pyplot as plt import seaborn as sns . Enable Pandas progress_apply so that we can get progress bars for Pandas operations . tqdm.pandas() . Read and clean the PubChem data . df = pd.read_csv(&quot;data/AID_1645841_datatable.csv&quot;,skiprows=[1,2,3,4,5],low_memory=False) . df . PUBCHEM_RESULT_TAG PUBCHEM_SID PUBCHEM_CID PUBCHEM_ACTIVITY_OUTCOME PUBCHEM_ACTIVITY_SCORE PUBCHEM_ACTIVITY_URL PUBCHEM_ASSAYDATA_COMMENT Phenotype-Replicate_1 Potency-Replicate_1 Efficacy-Replicate_1 ... Activity at 0.910 uM-Replicate_5 Activity at 1.182 uM-Replicate_5 Activity at 2.302 uM-Replicate_5 Activity at 4.834 uM-Replicate_5 Activity at 11.49 uM-Replicate_5 Activity at 23.94 uM-Replicate_5 Activity at 57.45 uM-Replicate_5 Activity at 115.4 uM-Replicate_5 Activity at 193.5 uM-Replicate_5 Activity at 288.3 uM-Replicate_5 . 0 1 | 104223880 | 197033.0 | Active | 43 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 10.6840 | 136.1930 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1 2 | 11111456 | 5281670.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2 3 | 11113977 | 6604832.0 | Inconclusive | 10 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 37.9083 | 105.9830 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 3 4 | 124879150 | 5280443.0 | Active | 84 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 6.0081 | 112.7240 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 4 5 | 124879975 | 836.0 | Active | 63 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 3.0112 | 57.7747 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 5237 5238 | 90341041 | 11957637.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5238 5239 | 90341069 | 4906.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5239 5240 | 90341160 | 5593.0 | Active | 42 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 10.6840 | 100.9580 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5240 5241 | 90341654 | 2968.0 | Inconclusive | 10 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 1.3450 | 68.4438 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5241 5242 | 90341795 | 108107.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Activator | 30.1116 | 70.1788 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5242 rows × 203 columns . Note that the data file doesn&#39;t have chemical structures as SMILES strings. We&#39;re going to add those using the pubchempy library, which can look up the chemical structure based on the PUBCHEM_CID field in our dataframe. This is great, but the pubchempy service will have problems if we pass it a null value. Let&#39;s check and see if we have any null values in our PUBCHEM_CID column. . sum(df.PUBCHEM_CID.isna()) . 4 . We have four null values. Let&#39;s look at those rows. . df[df.PUBCHEM_CID.isna()] . PUBCHEM_RESULT_TAG PUBCHEM_SID PUBCHEM_CID PUBCHEM_ACTIVITY_OUTCOME PUBCHEM_ACTIVITY_SCORE PUBCHEM_ACTIVITY_URL PUBCHEM_ASSAYDATA_COMMENT Phenotype-Replicate_1 Potency-Replicate_1 Efficacy-Replicate_1 ... Activity at 0.910 uM-Replicate_5 Activity at 1.182 uM-Replicate_5 Activity at 2.302 uM-Replicate_5 Activity at 4.834 uM-Replicate_5 Activity at 11.49 uM-Replicate_5 Activity at 23.94 uM-Replicate_5 Activity at 57.45 uM-Replicate_5 Activity at 115.4 uM-Replicate_5 Activity at 193.5 uM-Replicate_5 Activity at 288.3 uM-Replicate_5 . 173 174 | 144206496 | NaN | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1498 1499 | 170465762 | NaN | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2611 2612 | 170466890 | NaN | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2886 2887 | 225144377 | NaN | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 4 rows × 203 columns . We can drop the four rows where PUBCHEM_CID is null. . df.dropna(subset=[&quot;PUBCHEM_CID&quot;],inplace=True) . df . PUBCHEM_RESULT_TAG PUBCHEM_SID PUBCHEM_CID PUBCHEM_ACTIVITY_OUTCOME PUBCHEM_ACTIVITY_SCORE PUBCHEM_ACTIVITY_URL PUBCHEM_ASSAYDATA_COMMENT Phenotype-Replicate_1 Potency-Replicate_1 Efficacy-Replicate_1 ... Activity at 0.910 uM-Replicate_5 Activity at 1.182 uM-Replicate_5 Activity at 2.302 uM-Replicate_5 Activity at 4.834 uM-Replicate_5 Activity at 11.49 uM-Replicate_5 Activity at 23.94 uM-Replicate_5 Activity at 57.45 uM-Replicate_5 Activity at 115.4 uM-Replicate_5 Activity at 193.5 uM-Replicate_5 Activity at 288.3 uM-Replicate_5 . 0 1 | 104223880 | 197033.0 | Active | 43 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 10.6840 | 136.1930 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1 2 | 11111456 | 5281670.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2 3 | 11113977 | 6604832.0 | Inconclusive | 10 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 37.9083 | 105.9830 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 3 4 | 124879150 | 5280443.0 | Active | 84 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 6.0081 | 112.7240 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 4 5 | 124879975 | 836.0 | Active | 63 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 3.0112 | 57.7747 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 5237 5238 | 90341041 | 11957637.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5238 5239 | 90341069 | 4906.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inactive | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5239 5240 | 90341160 | 5593.0 | Active | 42 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 10.6840 | 100.9580 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5240 5241 | 90341654 | 2968.0 | Inconclusive | 10 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Inhibitor | 1.3450 | 68.4438 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5241 5242 | 90341795 | 108107.0 | Inactive | 0 | http://assay.nih.gov/htsws/rest/display/p450-i... | NaN | Activator | 30.1116 | 70.1788 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5238 rows × 203 columns . In order to lookup a structure based on PUBCHEM_CID the PUBCHEM_CID field must be an integer. Let&#39;s take a look at the datatypes for our dataframe. . df.dtypes . PUBCHEM_RESULT_TAG int64 PUBCHEM_SID int64 PUBCHEM_CID float64 PUBCHEM_ACTIVITY_OUTCOME object PUBCHEM_ACTIVITY_SCORE int64 ... Activity at 23.94 uM-Replicate_5 float64 Activity at 57.45 uM-Replicate_5 float64 Activity at 115.4 uM-Replicate_5 float64 Activity at 193.5 uM-Replicate_5 float64 Activity at 288.3 uM-Replicate_5 float64 Length: 203, dtype: object . The PUBCHEM_CID field is a float64, which is not what we want. Let&#39;s convert that column to an integer. . df.PUBCHEM_CID = df.PUBCHEM_CID.astype(int) . The field we want to model is Phenotype-Replicate_1 which takes one of three values. Let&#39;s look at the possible values and their distribution. We can see that the class Activator is somewhat underrepresented. We&#39;ll start by building a model with the data as provided. Once we&#39;ve done this, we&#39;ll also take a look at whether we can improve our model by employing strategies to compensate for the data imbalance. . df[&#39;Phenotype-Replicate_1&#39;].value_counts(normalize=True) . Inhibitor 0.580374 Inactive 0.354716 Activator 0.064910 Name: Phenotype-Replicate_1, dtype: float64 . In order to build our model, we need the column were predicting to be represented as numeric values. We can convert the text labels to numbers using the LabelEncoder method from skikit-learn. . labels = df[&#39;Phenotype-Replicate_1&#39;].unique().tolist() . le = LabelEncoder() le.fit(labels) df[&#39;label&#39;] = le.transform(df[&#39;Phenotype-Replicate_1&#39;]) . Our dataframe has a bunch of extra fields that are not necessary for this analysis. Let&#39;s simplify and create a new dataframe with only fields we care about. . data_df = df[[&#39;PUBCHEM_CID&#39;,&#39;Phenotype-Replicate_1&#39;,&#39;label&#39;]].copy() data_df . PUBCHEM_CID Phenotype-Replicate_1 label . 0 197033 | Inhibitor | 2 | . 1 5281670 | Inactive | 1 | . 2 6604832 | Inhibitor | 2 | . 3 5280443 | Inhibitor | 2 | . 4 836 | Inhibitor | 2 | . ... ... | ... | ... | . 5237 11957637 | Inactive | 1 | . 5238 4906 | Inactive | 1 | . 5239 5593 | Inhibitor | 2 | . 5240 2968 | Inhibitor | 2 | . 5241 108107 | Activator | 0 | . 5238 rows × 3 columns . Add chemical structures to the PubChem data . Now we&#39;ll use pubchempy to look up chemical structures based on PUBCHEM_CID and add them to our dataframe. In order to keep the PubChem server happy, we&#39;ll break the PUBCHEM_CID list into chunks of 100. . cmpd_list = [] num_chunks = len(df)/100 for chunk in tqdm(np.array_split(data_df.PUBCHEM_CID,num_chunks)): cmpd_list.append(pcp.get_compounds(chunk.tolist())) . We collected the chemical structures in a list of lists. We need to flatten this into a single list. The operation works something like this . [[1,2,3],[4,5,6],[7,8,9]] -&gt; [1,2,3,4,5,6,7,8,9] . data_df[&#39;Compound&#39;] = list(itertools.chain(*cmpd_list)) . Extract the SMILES from the Compound objects in the Compound column. . data_df[&#39;SMILES&#39;] = [x.canonical_smiles for x in data_df.Compound] . Calculate molecular descriptors . Create a DescriptorGen object for generating molecular descriptors. . desc_gen = DescriptorGen() . Add the descriptors to the dataframe. . data_df[&#39;desc&#39;] = data_df.SMILES.progress_apply(desc_gen.from_smiles) . Split the data into training and test sets . train, test = train_test_split(data_df) train_X = np.stack(train.desc) train_y = train.label test_X = np.stack(test.desc) test_y = test.label . Create and evaluate a machine learning model . Intstantiate a LighGBM classifier | Train the model | Predict on the test set | . lgbm = LGBMClassifier() lgbm.fit(train_X, train_y) pred = lgbm.predict_proba(test_X) . Evaluate model performance using the ROC AUC score. Note that this is a little different with a multiclass classifer. We specify class=&#39;ovo&#39; which means that we are evaluating &quot;one vs one&quot;. We evaluate the AUC for all pairs of classes. The argument average=&#39;macro&#39; indicates that the reported AUC is the average of all of the one vs one comparisons. . roc_auc_score(test_y,pred,multi_class=&#39;ovo&#39;,average=&#39;macro&#39;) . 0.7514670445236412 . We can also plot a confusion matrix to examine the model&#39;s performance on each of the three classes. . sns.set_style(&quot;white&quot;) sns.set_context(&#39;talk&#39;) plt.rcParams[&quot;figure.figsize&quot;] = (8,8) plot_confusion_matrix(lgbm,test_X,test_y,display_labels=sorted(labels),cmap=plt.cm.Blues) . &lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14ce358b0&gt; . Use oversampling to compensate for imbalanced data . Load the imbalanced-learn library to perform oversampling. In a simple oversampling approach we repeated sample the imbalanced class(es) to create a balanced dataset. . from imblearn.over_sampling import RandomOverSampler . We will create an oversampling object and use it to resample our training set. . ros = RandomOverSampler() resample_X, resample_y = ros.fit_resample(train_X,train_y) . Recall that our original training set is somewhat imbalanced. The minority class (0 or Activator) only accounts for ~7% of the data. . pd.Series(train_y).value_counts() . 2 2263 1 1394 0 271 Name: label, dtype: int64 . After oversampling the dataset is balanced. . pd.Series(resample_y).value_counts() . 0 2263 1 2263 2 2263 Name: label, dtype: int64 . Build a model with the balanced, oversampled data . resample_lgbm = LGBMClassifier() resample_lgbm.fit(resample_X, resample_y) . LGBMClassifier() . Make a prediction with the new model, built with the resampled data. . resample_pred = resample_lgbm.predict_proba(test_X) roc_auc_score(test_y,resample_pred,multi_class=&#39;ovr&#39;,average=&#39;macro&#39;) . 0.7831851902058725 . As above, we can plot a confusion matrix to examine the performance of the classifier trained on the oversampled data. Let&#39;s put the two confusion matrices side by side to compare. . sns.set_style(&quot;white&quot;) sns.set_context(&#39;talk&#39;) classifiers = [lgbm,resample_lgbm] titles = [&quot;Standard&quot;,&quot;Oversampled&quot;] fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5)) for cls,ax,title in zip(classifiers, axes, titles): plot_confusion_matrix(cls,test_X,test_y,display_labels=sorted(labels),cmap=plt.cm.Blues,ax=ax) ax.title.set_text(title) plt.tight_layout() . Comparing the standard and oversampled models . Let&#39;s see if there is a difference in AUC between the Standard and Resampled models. In order to compare we&#39;ll perform ten rounds of cross validation. . res = [] for i in tqdm(range(0,10)): # split the data into training and test sets train, test = train_test_split(data_df) train_X = np.stack(train.desc) train_y = train.label test_X = np.stack(test.desc) test_y = test.label # Create the standard model lgbm = LGBMClassifier() lgbm.fit(train_X,train_y) pred = lgbm.predict_proba(test_X) auc = roc_auc_score(test_y,pred,multi_class=&#39;ovo&#39;,average=&#39;macro&#39;) # Create the resampled model resample_lgbm = LGBMClassifier() resample_X, resample_y = ros.fit_resample(train_X,train_y) resample_lgbm.fit(resample_X, resample_y) resample_pred = resample_lgbm.predict_proba(test_X) resample_auc = roc_auc_score(test_y,resample_pred,multi_class=&#39;ovr&#39;,average=&#39;macro&#39;) res.append([auc, resample_auc]) . Create a dataframe with the AUC values using the Standard and Oversampled models . res = np.array(res) res_df = pd.DataFrame(res,columns=[&quot;Standard&quot;,&quot;Oversampled&quot;]) . res_df.head() . Standard Oversampled . 0 0.734876 | 0.771596 | . 1 0.756343 | 0.773071 | . 2 0.759373 | 0.777874 | . 3 0.759996 | 0.789183 | . 4 0.753852 | 0.792555 | . Reformat the dataframe to combine the two columns in res_df . melt_df = res_df.melt() melt_df.columns = [&quot;Method&quot;,&quot;AUC&quot;] melt_df . Method AUC . 0 Standard | 0.734876 | . 1 Standard | 0.756343 | . 2 Standard | 0.759373 | . 3 Standard | 0.759996 | . 4 Standard | 0.753852 | . 5 Standard | 0.731752 | . 6 Standard | 0.756979 | . 7 Standard | 0.747256 | . 8 Standard | 0.746451 | . 9 Standard | 0.743962 | . 10 Oversampled | 0.771596 | . 11 Oversampled | 0.773071 | . 12 Oversampled | 0.777874 | . 13 Oversampled | 0.789183 | . 14 Oversampled | 0.792555 | . 15 Oversampled | 0.755783 | . 16 Oversampled | 0.775097 | . 17 Oversampled | 0.773057 | . 18 Oversampled | 0.775309 | . 19 Oversampled | 0.782287 | . Plot the AUC distributions for the Standard and Oversampled models as a kernel density estimate (KDE) . sns.set(rc={&#39;figure.figsize&#39;: (10, 10)}) sns.set_context(&#39;talk&#39;) sns.kdeplot(x=&quot;AUC&quot;,hue=&quot;Method&quot;,data=melt_df); . Another way of comparing the distributions is to use the plot_paired method available in the pingouin library. Note that the AUC for the Resampled method is always greater than that for the Standard method. . from pingouin import wilcoxon, plot_paired . melt_df[&#39;cycle&#39;] = list(range(0,10))+list(range(0,10)) plot_paired(data=melt_df,dv=&quot;AUC&quot;,within=&quot;Method&quot;,subject=&quot;cycle&quot;); . In order to compare distributions, we sometime perform a t-test. However, a t-test assumes that the data is normally distributed. Since we can&#39;t make this assumption, we can use the Wilcoxon ranked sum test, which is the non-parametric equivalent to the t-test. The pingouin library provides a convenient implementation in the wilcoxon function. As we can see from the p-value in the table below, the difference in the means of the distributions is statistically significant. . wilcoxon(res_df.Standard,res_df.Oversampled) . W-val alternative p-val RBC CLES . Wilcoxon 0.0 | two-sided | 0.001953 | -1.0 | 0.04 | .",
            "url": "https://patwalters.github.io/practicalcheminformatics/jupyter/multiclass/pubchem/imbalanced/2021/08/28/multiclass-classification.html",
            "relUrl": "/jupyter/multiclass/pubchem/imbalanced/2021/08/28/multiclass-classification.html",
            "date": " • Aug 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Automatic Analog Generation With Common R-group Replacements",
            "content": "In a recent paper, Kosuke Takeuchi, Ryo Kunimoto, and Jürgen Bajorath report a database of R-group replacements. The authors analyzed the ChEMBL database and found the groups that were most commonly used to replace the 500 most common substituents. This seems like an interesting resource, and I wanted to put together a quick way of trying it out on a molecule of interest. As a test, I put together this notebook. . If your primarily interested in just running the notebook, just scroll down to the label Input Data Here and put in the SMILES for your molecule of interest and its core, then just &quot;Run All&quot;. . import xmltodict from collections import defaultdict from rdkit import Chem from rdkit.Chem import AllChem from rdkit.Chem import ReplaceCore, GetMolFrags, ReplaceSubstructs, CombineMols from itertools import product import numpy as np import pandas as pd . A function to convert SMILES to canonical form. This will enable us to look up replacements for specific functional groups (see below). . def smi2cansmi(smi): mol = Chem.MolFromSmiles(smi) if mol: for atm in mol.GetAtoms(): atm.SetIsotope(0) return Chem.MolToSmiles(mol) else: return None . The data from Takeuchi et al is provided as an XML file. In order to use this data we&#39;ll convert it into a Python dictionary. There may be a more efficient way to do this. I have to admit that my XML skills are a bit rusty. . def generate_replacement_dictionary(replacement_xml_file): ifs = open(replacement_xml_file) xml = ifs.read() d = xmltodict.parse(xml) replacement_dict = defaultdict() for k in d[&#39;R_replacements&#39;][&#39;center&#39;]: fl = k[&#39;first_layer&#39;] if type(fl) is not list: fl = [fl] first_layer = [a[&#39;@SMILES&#39;] for a in fl] sl = [ x for x in [a.get(&#39;second_layer&#39;) for a in fl] if x] second_layer = [] for row in sl: if type(row) is not list: row = [row] for r in row: second_layer.append(r[&#39;@SMILES&#39;]) replacement_dict[smi2cansmi(k[&#39;@SMILES&#39;])] = [first_layer, second_layer] return replacement_dict . Read the XML file and convert it to a dictionary. . replacement_dict = generate_replacement_dictionary(&quot;data/top500_R_replacements.xml&quot;) . The R-group database contains two entries for each R-group, level 1 replacements, which are replacements for the R-group, and level two replacements, which are &quot;replacements for replacements&quot;. Our dictionary contains a list where the first entry is the level 1 replacements and the second entry is the level 2 replacements. . replacement_dict[&quot;*O&quot;] . [[&#39;*OC&#39;, &#39;*N&#39;, &#39;*CO&#39;, &#39;*OC(C)=O&#39;, &#39;*C(=O)NO&#39;], [&#39;*Cl&#39;, &#39;*OCC&#39;, &#39;*NC&#39;, &#39;*NC(C)=O&#39;, &#39;*C(C)O&#39;, &#39;*C(C)(C)O&#39;, &#39;*CC(=O)NO&#39;]] . At this point we can make a choice and either use only the level 1 replacements or use the level 1 and level 2 replacements. If we set &quot;use_second_layer&quot; to True in the cell below, we will use both level 1 and level 2 replacements. If we set it to False, we&#39;ll use only the level 1 replacements. . use_second_layer = True . Define a function to get replacements for a substituent. Note that we use the smi2cansmi function we created above. This function now includes a change suggested in the comments by James Wallace (thanks!). . def get_replacements(smi, replacement_dict): cansmi = smi2cansmi(smi) return replacement_dict.get(cansmi, [[cansmi], [cansmi]]) . get_replacements(&quot;*CC&quot;,replacement_dict) . [[&#39;*C(C)C&#39;, &#39;*CCC&#39;, &#39;*C1CC1&#39;, &#39;*CCCC&#39;, &#39;*C=C&#39;], [&#39;*C1CCCCC1&#39;, &#39;*CC(C)C&#39;, &#39;*CCCCC&#39;, &#39;*C1CCC1&#39;, &#39;*C1CCCO1&#39;, &#39;*CCCCCC&#39;, &#39;*CCC(C)C&#39;]] . As a test, we&#39;ll define a target molecule and its core. . Input Data Here . smiles_target = &quot;c1cc(ccc1c2c(n(cn2)CC3CC3)c4ccnc(n4)N)F&quot; core_smarts = &quot;n1cncc1&quot; . mol_target = Chem.MolFromSmiles(smiles_target) mol_target . mol_core = Chem.MolFromSmarts(core_smarts) mol_core . As a sanity check, we will make sure the core matches the target molecule. . mol_target.HasSubstructMatch(mol_core) . True . Given a molecule and core, we can use the function ReplaceCore from the RDKit to get the sidechains. . sidechain_mol = ReplaceCore(mol_target,mol_core,labelByIndex=True) sidechain_mol . The ReplaceCore function puts all of the sidechains into one molecule. We can split these up with the function GetMolFrags. Note that the fragments are labeled with the core atom to which they were attached. This will be useful when we start putting things back together. Also note that the fragment in the center doesn&#39;t appear to have a label. This is because that substituent was attached to atom 0 and the RDKit doesn&#39;t label isotopes that are 0. . sidechain_frag_list = GetMolFrags(sidechain_mol,asMols=True) Chem.Draw.MolsToGridImage(sidechain_frag_list) . Define a function to get the attachment atom for a substituent. . def get_connect_idx(mol): return max([x.GetIsotope() for x in mol.GetAtoms()]) . attach_idx = [get_connect_idx(x) for x in sidechain_frag_list] attach_idx . [3, 0, 4] . Now lets get the SMILES for each of the substituents. Note that the SMILES still have isotope labels indicating the attachment points. This could create a problem when we try to find replacements. Fortunately, the smi2cansmi function defined above strips out the isotope labels. . sidechain_smiles = [Chem.MolToSmiles(x) for x in sidechain_frag_list] sidechain_smiles . [&#39;[3*]c1ccc(F)cc1&#39;, &#39;*CC1CC1&#39;, &#39;[4*]c1ccnc(N)n1&#39;] . With the R-group SMILES in hand, we can just lookup the replacements . replacement_smiles = [get_replacements(x,replacement_dict) for x in sidechain_smiles] replacement_smiles . [[[&#39;*c1ccc(Cl)cc1&#39;, &#39;*c1ccc(OC)cc1&#39;, &#39;*c1cccc(F)c1&#39;, &#39;*c1ccccc1F&#39;, &#39;*c1ccc(F)c(F)c1&#39;], [&#39;*c1ccc(C)cc1&#39;, &#39;*c1cccc(Cl)c1&#39;, &#39;*c1cccc(OC)c1&#39;, &#39;*c1ccccc1OC&#39;, &#39;*c1cc(F)cc(F)c1&#39;, &#39;*c1c(F)cccc1F&#39;]], [[&#39;*CC&#39;], [&#39;*C(C)C&#39;, &#39;*CCC&#39;]], [[&#39;*c1ccncc1&#39;], [&#39;*c1cccnc1&#39;, &#39;*c1ccnc(C)c1&#39;]]] . Now we can decide whether we want to use the layer 2 replacements. . if use_second_layer: tmp_smiles = [a+b for a,b in replacement_smiles] else: tmp_smiles = [x[0] for x in replacement_smiles] replacement_smiles = tmp_smiles . We&#39;ll add the original sidechain SMILES at the head of each of the replacement lists. . clean_sidechain_smiles = [smi2cansmi(x) for x in sidechain_smiles] tmp_list = [] for i,j in zip(clean_sidechain_smiles,replacement_smiles): tmp_list.append([i]+j) replacement_smiles = tmp_list . At this point we have all of the replacement R-groups, now we want to put all combinations of these R-groups together to make new molecules. We need to define a function that will delete the dummy atom at the attachment point of each sidechain and define an attachment point. The attachment point will be defined by setting the atom map on the attachment atom to 1. . def prep_sidechain(smi): mol = Chem.MolFromSmiles(smi) rw_mol = Chem.RWMol(mol) remove_idx = -1 for atm in rw_mol.GetAtoms(): if atm.GetAtomicNum() == 0: remove_idx = atm.GetIdx() for nbr in atm.GetNeighbors(): nbr.SetAtomMapNum(1) rw_mol.RemoveAtom(remove_idx) Chem.SanitizeMol(rw_mol) return rw_mol . prep_sidechain(&#39;*c1ccc(Cl)cc1&#39;) . Now we just need a function to glue the pieces together. . def make_analogs(core,attach_pts,sidechains): prod_list = [] for c in product(*sidechains): sidechain_mol_list = [prep_sidechain(x) for x in c] mol = Chem.RWMol(core) for start_atm,m in zip(attach_pts,sidechain_mol_list): mol = Chem.RWMol(CombineMols(mol,m)) end_atm = -1 for atm in mol.GetAtoms(): if atm.GetAtomMapNum() == 1: end_atm = atm.GetIdx() mol.AddBond(start_atm, end_atm, order=Chem.rdchem.BondType.SINGLE) for atm in mol.GetAtoms(): atm.SetAtomMapNum(0) prod_list.append(Chem.MolToSmiles(mol)) return prod_list . Generate a list of analogs for our target molecule . analog_list = make_analogs(mol_core,attach_idx,replacement_smiles) len(analog_list) . 192 . Scroll through the replacements. . mol_list = [Chem.MolFromSmiles(x) for x in analog_list] AllChem.Compute2DCoords(mol_core) [AllChem.GenerateDepictionMatching2DStructure(x,mol_core) for x in mol_list] # Display the grid Chem.Draw.MolsToGridImage(mol_list[:25],molsPerRow=5) . There are still a few things to do here. I don&#39;t think this code will handle stereochemistry and there still may be a few edge cases. Either way, I&#39;ve already found this useful. Thanks Jürgen! .",
            "url": "https://patwalters.github.io/practicalcheminformatics/jupyter/chembl/2021/07/05/replace-rgroups.html",
            "relUrl": "/jupyter/chembl/2021/07/05/replace-rgroups.html",
            "date": " • Jul 5, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Assessing Interpretable Models",
            "content": "Introduction . Given the recent uptick in the number of papers on interpretable models, I thought it would be interesting to create a simple example showing how one can highlight atoms that are predicted to be critical to a particular property or activity. This example is motivated by the recent paper Benchmarks for interpretation of QSAR models by Mariia Matveieva and Pavel Polishchuk. In this paper, the authors lay out benchmark datasets and evaluation metrics for model interpretability. In this post, we&#39;ll build a simple machine learning model and use some techniques implemented in the RDKit to evaluate the contributions of specific atoms in a molecule to a particular activity. . One of the things I like about the paper by Matveieva and Polishchuk is that it defines some simple cases where the answer is known, and the activity should be explainable. We will consider the simplest case where we create a model to predict the number of nitrogen atoms in a molecule. Once we&#39;ve defined the model, we can systematically remove the contributions of one atom at a time, predict the activity of the modified molecule and see if the predicted activity changes. The atoms whose absence brings about the largest changes are considered to be the most important. . We begin by importing the necessary Python libraries. . import pandas as pd from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem import PandasTools from rdkit.Chem import AllChem from rdkit.Chem.Draw import SimilarityMaps from xgboost import XGBRegressor from tqdm.notebook import tqdm import numpy as np import seaborn as sns import io from PIL import Image from sklearn.metrics import roc_curve, roc_auc_score from rdkit.Chem.Draw import rdMolDraw2D from IPython.display import SVG from collections import defaultdict . Loading the Data . The GitHub repo for the paper above contains several example datasets. The file N_train_lbl.sdf contains a set of molecules with a data field &quot;activity&quot; containing the number of nitrogen atoms in the molecule. We will use this as the y value for our predictive model. It also has a field, &quot;lbls&quot;, containing a list of 1 and 0 values, with 1 for nitrogen atoms and 0 for other elements. We will use this field to evaluate the validity of the importance measures. . To start, we&#39;ll read the training data, convert the &quot;activity&quot; field to an integer, and add a fingerprint column. . df_train = PandasTools.LoadSDF(&quot;data/N_train_lbl.sdf.gz&quot;) df_train.activity = df_train.activity.astype(int) df_train[&#39;fp&#39;] = [AllChem.GetMorganFingerprintAsBitVect(x, 2) for x in tqdm(df_train.ROMol)] . df_train.head(1) . N ids activity lbls ID ROMol fp . 0 2 | 19,23 | 2 | 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,... | CHEMBL379993 | | [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... | . In a similar fashion, we can read the test data, convert the &quot;activity&quot; field to an integer and add a fingerprint column . df_test = PandasTools.LoadSDF(&quot;data/N_test_lbl.sdf.gz&quot;) df_test.activity = df_test.activity.astype(int) df_test[&#39;fp&#39;] = [AllChem.GetMorganFingerprintAsBitVect(x, 2) for x in tqdm(df_test.ROMol)] . In order to build a model, we need to extract the X and y variables from the training dataframe. . t.rain_X = np.asarray(list(df_train.fp.values)) train_y = df_train.activity.values . Building a Simple Machine Learning Model . With a few lines of code, we can build an XGBoost regression model. . xgb = XGBRegressor() . xgb.fit(train_X,train_y) . XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1, importance_type=&#39;gain&#39;, interaction_constraints=&#39;&#39;, learning_rate=0.300000012, max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan, monotone_constraints=&#39;()&#39;, n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#39;exact&#39;, validate_parameters=1, verbosity=None) . Extract the X and y variables from the test dataframe. . test_X = np.asarray(list(df_test.fp.values)) test_y = df_test.activity.values . Predict on the test set . test_pred = xgb.predict(test_X) . Plot the predictions as a violinplot. We could do this as a scatterplot, but a lot of points would be superimposed and it would be difficult to understand the spread of the predictions. . sns.violinplot(x=test_y, y=test_pred); . Intepreting the Model . Now that we&#39;ve built a model, we will take a look at one way that we can interpret the model. We&#39;ll start by grabbing the first molecule in the training set. We notice this molecule has 2 nitrogen atoms, with indices 18 and 22. . example_mol = Chem.Mol(df_train.ROMol.values[0]) d2d = rdMolDraw2D.MolDraw2DSVG(500,500) d2d.drawOptions().addAtomIndices=True d2d.DrawMolecule(example_mol) d2d.FinishDrawing() SVG(d2d.GetDrawingText()) . We can generate a fingerprint for this molecule and use our model to predict its activity (number of nitrogens). Note that the number of nitrogens is predicted to be 1.8, rather than 2. . example_fp = AllChem.GetMorganFingerprintAsBitVect(example_mol,2) example_pred = xgb.predict(np.array([example_fp]))[0] example_pred . 1.810564 . One way of assessing the importance of atoms to a predicted activity is to &quot;mask&quot; each atom and predict the activity using a fingerprint generated with the masked atom. If the prediction with the &quot;masked&quot; atom is similar to the prediction with the original molecule, that atom has little impact on the prediction. On the other hand, if masking the atom makes a large change in the prediction, we consider that atom important. We can use the function SimilarityMaps.GetMorganFingerprint to generate a fingerprint with an atom masked. This function takes two arguments, the input molecule, and the index of the atom to be masked. . In the code block below, we loop over atoms, generate a fingerprint with each atom masked, and generate a prediction with the masked fingerprint. At each iteration, we record the predicted activity and &quot;delta&quot;, the difference between the activity of the original molecule with no atoms masked and the new molecule with one atom masked. This data is collected and displayed in a dataframe that is sorted by delta. As we can see in the resulting table, the two nitrogen atoms 18 and 22, have the highest values for delta. . res = [] for atm in example_mol.GetAtoms(): idx = atm.GetIdx() fp = SimilarityMaps.GetMorganFingerprint(example_mol,idx) pred_val = xgb.predict(np.array([fp]))[0] delta = example_pred - pred_val res.append([atm.GetSymbol(),idx,pred_val,delta]) tmp_df = pd.DataFrame(res,columns = [&quot;Atom Type&quot;,&quot;Atom Index&quot;,&quot;Predicted Value&quot;,&quot;Delta&quot;]) tmp_df.sort_values(&quot;Delta&quot;,ascending=False) . Atom Type Atom Index Predicted Value Delta . 18 N | 18 | 0.631518 | 1.179046 | . 22 N | 22 | 0.659471 | 1.151093 | . 21 C | 21 | 1.429062 | 0.381502 | . 29 C | 29 | 1.438288 | 0.372276 | . 27 C | 27 | 1.445818 | 0.364746 | . 23 C | 23 | 1.445818 | 0.364746 | . 28 C | 28 | 1.523000 | 0.287564 | . 11 C | 11 | 1.527700 | 0.282864 | . 10 C | 10 | 1.527700 | 0.282864 | . 20 O | 20 | 1.533833 | 0.276731 | . 19 C | 19 | 1.537342 | 0.273222 | . 5 C | 5 | 1.555402 | 0.255162 | . 26 C | 26 | 1.609091 | 0.201473 | . 24 C | 24 | 1.609091 | 0.201473 | . 17 C | 17 | 1.632672 | 0.177892 | . 12 C | 12 | 1.632672 | 0.177892 | . 13 C | 13 | 1.651169 | 0.159395 | . 16 C | 16 | 1.651169 | 0.159395 | . 7 C | 7 | 1.719232 | 0.091332 | . 2 C | 2 | 1.719232 | 0.091332 | . 3 C | 3 | 1.725852 | 0.084712 | . 4 C | 4 | 1.725852 | 0.084712 | . 1 O | 1 | 1.738884 | 0.071680 | . 0 C | 0 | 1.803944 | 0.006620 | . 9 C | 9 | 1.803944 | 0.006620 | . 6 C | 6 | 1.810564 | 0.000000 | . 8 O | 8 | 1.823596 | -0.013032 | . 25 O | 25 | 1.839605 | -0.029041 | . 14 C | 14 | 1.856854 | -0.046290 | . 15 F | 15 | 1.856854 | -0.046290 | . Using Similarity Maps to Interpret Models . Now we&#39;ll use the SimilarityMaps feature from the RDKit to project the importance of each atom onto the chemical structure. As mentioned above, this method iterates over atoms, removes the contributions of each atom, and uses the model to predict the molecule&#39;s activity. If the activity changes, we consider that atom to be important. This importance is the used to create a set of weights for atoms that is displayed on top of the structure. The darker colored atoms are considered to be more important. . Define some functions to display the similarity map for the predictions, mostly lifted from Greg Landrum&#39;s blog post . def show_png(data): bio = io.BytesIO(data) img = Image.open(bio) return img def get_pred(fp, pred_function): fp = np.array([list(fp)]) return pred_function(fp)[0] def plot_similarity_map(mol, model): d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapForModel(mol, SimilarityMaps.GetMorganFingerprint, lambda x : get_pred(x, model.predict), draw2d=d) d.FinishDrawing() return d . Display the similarity map for the predictions. The variable test_row in the table below corresponds to the row in test_df that will be displayed. . test_row = 1 test_mol = df_test.ROMol.values[test_row] res = plot_similarity_map(test_mol,xgb); show_png(res.GetDrawingText()) . Evaluating the Interpretations . In this case we know the &quot;correct&quot; weights for each atom. Since we&#39;re predicting the total number of nitrogen atoms, the nitrogen atoms should have a weight of 1 and the other atoms should have a weight of 0. We can evaluate the weights produced by the model by comparing them with the weights in the &quot;lbls&quot; column in the input dataframe. To get weights for each atom, we could use the code above. However, the RDKit provides a simpler solution. The function SimilarityMaps.GetAtomicWeightsForModel wraps the masking operation described above into a single line of code. . aw = SimilarityMaps.GetAtomicWeightsForModel(test_mol, SimilarityMaps.GetMorganFingerprint, lambda x : get_pred(x, xgb.predict)) aw = np.array(aw) . Convert the weights and associated atom types to a dataframe. For the test molecule in row 1, the two nitrogens have the largest weights. . wt_df = pd.DataFrame(zip([atm.GetSymbol() for atm in test_mol.GetAtoms()],aw),columns=[&quot;Symbol&quot;,&quot;Weight&quot;]) wt_df.sort_values(&quot;Weight&quot;,ascending=False) . Symbol Weight . 10 N | 0.964518 | . 26 N | 0.764683 | . 2 C | 0.289154 | . 3 C | 0.289154 | . 1 C | 0.289154 | . 11 C | 0.235727 | . 20 C | 0.222842 | . 12 C | 0.218294 | . 19 C | 0.214360 | . 25 C | 0.184042 | . 24 C | 0.184042 | . 21 C | 0.177596 | . 8 C | 0.164767 | . 7 C | 0.126218 | . 27 C | 0.019931 | . 28 O | 0.019931 | . 18 F | 0.000000 | . 0 C | 0.000000 | . 17 C | -0.017433 | . 16 C | -0.017433 | . 15 C | -0.017433 | . 13 C | -0.017433 | . 14 C | -0.017433 | . 23 C | -0.038800 | . 22 Cl | -0.039767 | . 9 C | -0.124386 | . 6 O | -0.162935 | . 4 O | -0.182587 | . 5 C | -0.262592 | . Now that we have a way of assigning labels to atoms, we can compare the weights with the &quot;correct&quot; weights, which are in the &quot;lbls&quot; field of the dataframe. . test_labels = df_test.lbls[test_row] test_label_array = np.fromstring(test_labels,sep=&quot;,&quot;,dtype=int) . test_label_array . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) . There are several ways that we can compare the predicted and actual weights. One of the simplest is to treat this as a classification problem and calculate the area under the Receiver Operating Characteristic (ROC) curve, which plots the false positive rate vs the true positive rate. . sns.set_context(&#39;talk&#39;) fpr, tpr, thresholds = roc_curve(test_label_array, aw) ax = sns.lineplot(x=fpr,y=tpr) ax.set_xlabel(&quot;False Positive Rate&quot;) ax.set_ylabel(&quot;True Positive Rate&quot;); . We can use sklearn to calculate the area under the ROC curve. . roc_auc_score(test_label_array,aw) . 1.0 . As Matveieva and Polishchuk point out, we&#39;re primarily concerned with the identifying the important atoms, and AUC considers the weights on all atoms. If we&#39;re only interested in the &quot;top N&quot; predictions, we can define a score that considers the validity of the relevant predictions. In this case, that would be the predictions of the nitrogen atoms. Matveieva and Polishchuk define a topn score as $$ frac{ sum{i}mi}{ sum{j}nj} $$ where $m{i}$ is the total number of ranked atoms in molecule i and $n_{i}$ is the total number of atoms correctly ranked by their contribution. Here&#39;s a quick Python function to calcuate the top_n score for a molecule. . def top_n(ref, pred): n = int(np.sum(ref)) top_ref_idx = ref.argsort()[-n:][::-1] top_pred_idx = pred.argsort()[-n:][::-1] num_common = len(set(top_ref_idx).intersection(set(top_pred_idx))) return num_common/float(n) . With this function in hand, let&#39;s calculate the AUC and top_n score for the first 100 test molecules. We&#39;ll also save a list of molecules with a top_n_score &lt; 1.0 so that we can examine then later. . auc_list = [] top_n_score_list = [] top_n_lt_1_list = [] idx = 0 for mol, label in tqdm(df_test[[&quot;ROMol&quot;,&quot;lbls&quot;]].head(100).values): aw = SimilarityMaps.GetAtomicWeightsForModel(mol, SimilarityMaps.GetMorganFingerprint, lambda x : get_pred(x, xgb.predict)) if label != &quot;NA&quot;: label_array = np.fromstring(label,sep=&quot;,&quot;,dtype=int) auc_list.append(roc_auc_score(label_array,aw)) top_n_score = top_n(label_array,np.array(aw)) top_n_score_list.append(top_n_score) if top_n_score &lt; 1: top_n_lt_1_list.append([idx,top_n_score]) idx+=1 print(f&quot;Mean AUC = {np.mean(auc_list):.2f}&quot;) print(f&quot;Mean top_n = {np.mean(top_n_score_list):.2f}&quot;) . Mean AUC = 0.99 Mean top_n = 0.93 . Create a dataframe with the rows where the top_n score was less than 1. It&#39;s interesting that in 15 of 100 cases, we fail to assign the nitrogens atoms as critical features. . pd.DataFrame(top_n_lt_1_list,columns=[&quot;Row&quot;,&quot;Top_n_score&quot;]) . Row Top_n_score . 0 7 | 0.500000 | . 1 10 | 0.500000 | . 2 21 | 0.666667 | . 3 28 | 0.750000 | . 4 29 | 0.800000 | . 5 33 | 0.666667 | . 6 44 | 0.666667 | . 7 59 | 0.333333 | . 8 60 | 0.000000 | . 9 66 | 0.500000 | . 10 71 | 0.666667 | . 11 76 | 0.750000 | . 12 79 | 0.666667 | . 13 84 | 0.750000 | . 14 87 | 0.666667 | . 15 94 | 0.666667 | . Let&#39;s define a debugging function that will enable us to compare the top n predictions with the top n labels. . def debug_row(df, idx): red = (1,0,0) blue = (0,0,1) mol = df.loc[[idx]].ROMol.values[0] mol = Chem.Mol(mol) label = df.loc[idx].lbls label_array = np.fromstring(label,sep=&quot;,&quot;,dtype=int) n = int(sum(label_array)) aw = SimilarityMaps.GetAtomicWeightsForModel(mol, SimilarityMaps.GetMorganFingerprint, lambda x : get_pred(x, xgb.predict)) aw = np.array(aw) top_idx = aw.argsort()[-n:][::-1] top_idx = [int(x) for x in top_idx] # set the drawing options d2d = rdMolDraw2D.MolDraw2DSVG(350,300) dos = d2d.drawOptions() dos.atomHighlightsAreCircles = True dos.fillHighlights=False # set the highlight color for the top n predicted atoms to red top_dict = defaultdict(list) highlight_rads = {} for t in top_idx: top_dict[t].append(red) # set the colors for the top n labeled atoms to red for a in label_array.argsort()[-n:]: top_dict[int(a)].append(blue) # set the radii for the highlight circles for k,v in top_dict.items(): highlight_rads[k] = 0.6 d2d.DrawMoleculeWithHighlights(mol,&quot; &quot;,dict(top_dict),{},highlight_rads,{}) d2d.FinishDrawing() return d2d . Here&#39;s the output from our debugging function. Correctly predicted atoms are shown as circles that are half red and half blue. Incorrectly predicted atoms are shown as red circles, atoms that are &quot;missed&quot; are shown as blue circles. . mistake_row = 7 res = debug_row(df_test,mistake_row) SVG(res.GetDrawingText()) . Conclusion . Hopefully, this post provides a brief introduction into how models can be interpreted and how the values interpreted from a model can be assessed. There&#39;s a lot more to be done here, but hopefully this code provides a place to get started. If you&#39;re interested in the critical assessment of model interpretability, I highly recommend these two papers. . Sheridan, Robert P. &quot;Interpretation of QSAR models by coloring atoms according to changes in predicted activity: how robust is it?.&quot; Journal of Chemical Information and Modeling 59.4 (2019): 1324-1337. https://doi.org/10.1021/acs.jcim.8b00825 . Matveieva M, Polishchuk P. Benchmarks for interpretation of QSAR models. Journal of Cheminformatics. 2021 Dec;13(1):1-20. https://doi.org/10.1186/s13321-021-00519-x .",
            "url": "https://patwalters.github.io/practicalcheminformatics/jupyter/ml/interpretability/2021/06/03/interpretable.html",
            "relUrl": "/jupyter/ml/interpretability/2021/06/03/interpretable.html",
            "date": " • Jun 3, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Fast Parallel Cheminformatics Workflows With Dask",
            "content": "In this post we&#39;ll take a look at how we can use Dask to parallelize and speed up Cheminformatics workflows with a couple of lines of code. As an example we&#39;ll write a scritpt to calculate the properties from Lipinski&#39;s Rule of 5. Just for fun, we&#39;ll also add in the number of rotatable bonds. We&#39;ll start by implementing a simple serial version, then modify that to run in parallel with Dask. . Single Processor Version . First we&#39;ll import the necessary Python libraries. . import pandas as pd from rdkit import Chem from rdkit.Chem import Descriptors . Let&#39;s ensure that that Pandas dataframes are displayed with an appropriate number of decimal places. . pd.options.display.float_format = &quot;{:,.2f}&quot;.format . Define a function to calculate the properties . def calc_r5(smiles): mol = Chem.MolFromSmiles(smiles) dummy = -9999.0 res = [dummy, dummy, dummy, dummy, dummy] if mol: res = [Descriptors.MolWt(mol),Descriptors.MolLogP(mol),Descriptors.NumHDonors(mol), Descriptors.NumHAcceptors(mol),Descriptors.NumRotatableBonds(mol)] return res . Read a SMILES file into a Pandas dataframe . infile_name = &quot;https://github.com/PatWalters/datafiles/blob/main/test.smi?raw=true&quot; df = pd.read_csv(infile_name,sep=&quot; &quot;,names=[&quot;SMILES&quot;,&quot;Name&quot;]) . Calculate the properties for the SMILES in the dataframe. . df[&#39;R5&#39;] = df.SMILES.apply(calc_r5) . Now we have all of the properties as a list in one column. This isn&#39;t what we want. However, we can use this trick to create new columns from the list. . df[[&quot;MW&quot;,&quot;LogP&quot;,&quot;HBD&quot;,&quot;HBA&quot;,&quot;Rot&quot;]] = df.R5.to_list() . df . SMILES Name R5 MW LogP HBD HBA Rot . 0 Br.CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1 | 675686 | [320.658, 3.877200000000003, 1, 2, 3] | 320.66 | 3.88 | 1 | 2 | 3 | . 1 Br.Cc1ccc(Sc2ccccc2N3CCNCC3)c(C)c1 | 1379657 | [379.3670000000002, 4.442140000000004, 1, 3, 3] | 379.37 | 4.44 | 1 | 3 | 3 | . 2 Br.CN(C)CCCC1(OCc2cc(ccc12)C#N)c3ccc(F)cc3 | 674732 | [405.31100000000004, 4.390880000000004, 0, 3, 5] | 405.31 | 4.39 | 0 | 3 | 5 | . 3 Br.CN1CCC[C@@H]1Cc2c[nH]c3ccc(CCS(=O)(=O)c4ccc... | 674954 | [463.4410000000002, 4.398900000000004, 1, 3, 6] | 463.44 | 4.40 | 1 | 3 | 6 | . 4 Br.COc1ccc2CN(C)CC[C@@]34C=C[C@H](O)C[C@@H]3Oc... | 443255 | [368.2710000000001, 2.4282000000000004, 1, 4, 1] | 368.27 | 2.43 | 1 | 4 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 95 CC(C)CC(N(C)C)C1(CCC1)c2ccc(Cl)cc2 | 358192 | [279.85499999999996, 4.738000000000005, 0, 1, 5] | 279.85 | 4.74 | 0 | 1 | 5 | . 96 CC(C)CC1(CC=C)C(=O)NC(=O)NC1=O | 2524 | [224.26, 0.9609999999999999, 2, 3, 4] | 224.26 | 0.96 | 2 | 3 | 4 | . 97 CC(C)Cc1ccc(cc1)C(C)C(=O)O | 11674 | [206.28499999999997, 3.073200000000001, 1, 1, 4] | 206.28 | 3.07 | 1 | 1 | 4 | . 98 CC(C)CCC[C@@H](C)[C@H]1CC[C@H]2 C(=C C=C/3 C[C... | 125294 | [384.6480000000003, 7.619000000000009, 1, 1, 6] | 384.65 | 7.62 | 1 | 1 | 6 | . 99 CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)O[C@H]... | 17347 | [505.63700000000034, 2.4028, 3, 7, 11] | 505.64 | 2.40 | 3 | 7 | 11 | . 100 rows × 8 columns . At this point, we no longer need the R5 column, so we can get rid of it. . df.drop(&quot;R5&quot;,axis=1,inplace=True) . Finally, we can write the results to a csv file. . df.to_csv(&quot;props.csv&quot;,index=False) . Parallel Version . In order to parallelize this calculation with Dask, we need an additional import. . import dask.dataframe as dd . We also need to convert the Pandas dataframe to a Dask dataframe. In the constructor for the Dask dataframe, we specify an argument &quot;npartitions&quot;, that defines the number of chunks to divide the dataframe into for the calculation. This seems to be most efficeint when we set &quot;npartitions&quot; to the number of processor cores. . num_cores = 8 ddf = dd.from_pandas(df,npartitions=num_cores) . Parallelization with Dask requires a function that accepts a dataframe as input. We can define a function that uses the &quot;apply&quot; from the serial version above. . def df_r5(df_in): return df_in.SMILES.apply(calc_r5) . Now we can parallelize our workflow with a single line of code. . df[&quot;R5&quot;] = ddf.map_partitions(df_r5,meta=&#39;float&#39;).compute(scheduler=&#39;processes&#39;) . We can use the same method we described above to split the &quot;R5&quot; column into multiple columns. . df[[&quot;MW&quot;,&quot;LogP&quot;,&quot;HBD&quot;,&quot;HBA&quot;,&quot;Rot&quot;]] = df.R5.to_list() df.drop(&quot;R5&quot;,axis=1,inplace=True) . Benchmarking . Let&#39;s take a look at how much of a speedup we can get by using Dask. To do this, we&#39;ll take a look at how long it takes to calculate the five properties above for 1 million molecules from the ZINC database. The input file is large so I didn&#39;t include it in this post. Here&#39;s the code I used to perform the benchmark. . import time df = pd.read_csv(&quot;zinc_1M.smi&quot;,sep=&quot; &quot;,names=[&quot;SMILES&quot;,&quot;Name&quot;]) runtime_res = [] for num_cores in range(1,9): ddf = dd.from_pandas(df,npartitions=num_cores) start = time.time() df[&quot;R5&quot;] = ddf.map_partitions(df_r5,meta=&#39;float&#39;).compute(scheduler=&#39;processes&#39;) elapsed = time.time()-start df[[&quot;MW&quot;,&quot;LogP&quot;,&quot;HBD&quot;,&quot;HBA&quot;,&quot;Rot&quot;]] = df.R5.to_list() df.drop(&quot;R5&quot;,axis=1,inplace=True) df.to_csv(&quot;props.csv&quot;,index=False,float_format=&quot;%0.2f&quot;) print(f&quot;{len(df)} molecules processed in {elapsed:0.2f} sec on {num_cores} cores&quot;) runtime_res.append([elapsed,num_cores]) . 1000000 molecules processed in 714.70 sec on 1 cores 1000000 molecules processed in 378.56 sec on 2 cores 1000000 molecules processed in 272.38 sec on 3 cores 1000000 molecules processed in 211.11 sec on 4 cores 1000000 molecules processed in 177.00 sec on 5 cores 1000000 molecules processed in 158.07 sec on 6 cores 1000000 molecules processed in 146.98 sec on 7 cores 1000000 molecules processed in 142.83 sec on 8 cores . Make a dataframe so that we can view the results. We&#39;ll add a column with the runtime ratio for n cores to 1 core. . runtime_df = pd.DataFrame(runtime_res,columns=[&quot;Runtime&quot;,&quot;Cores&quot;]) one_core_time = runtime_df.Runtime.values[0] runtime_df[&#39;Ratio&#39;] = one_core_time/runtime_df.Runtime . View the results. 5x speed-up with 8 cores, not too bad for one line of code. . runtime_df . Runtime Cores Ratio . 0 714.70 | 1 | 1.00 | . 1 378.56 | 2 | 1.89 | . 2 272.38 | 3 | 2.62 | . 3 211.11 | 4 | 3.39 | . 4 177.00 | 5 | 4.04 | . 5 158.07 | 6 | 4.52 | . 6 146.98 | 7 | 4.86 | . 7 142.83 | 8 | 5.00 | . Plot the results. . import seaborn as sns sns.set(rc={&#39;figure.figsize&#39;: (10, 10)}) sns.set_style(&#39;whitegrid&#39;) sns.set_context(&#39;talk&#39;) ax = sns.scatterplot(x=&quot;Cores&quot;,y=&quot;Runtime&quot;,data=runtime_df) ax.set(ylabel=&quot;Runtime (sec)&quot;); . Caveats . The method described here is only going to work for datasets that will fit into memory. You can use this method to process millions of molecules, but it won&#39;t work for billions. Dask has other methods for dealing with data that won&#39;t fit into memory. We&#39;ll save that discussion for another day. . Acknowledgments . I&#39;d like to thank Yutong Zhao, Greg Landrum, Peter St. John, and Maciek Wójcikowski for valuable advice. .",
            "url": "https://patwalters.github.io/practicalcheminformatics/jupyter/dask/parallel/2021/03/28/dask-cheminformatics.html",
            "relUrl": "/jupyter/dask/parallel/2021/03/28/dask-cheminformatics.html",
            "date": " • Mar 28, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I do Cheminformatics, sometimes I write about it. .",
          "url": "https://patwalters.github.io/practicalcheminformatics/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://patwalters.github.io/practicalcheminformatics/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}